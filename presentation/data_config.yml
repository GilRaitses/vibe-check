# Data Configuration for NYC Safety App Presentation
# Variables and metrics for generating visualizations

project:
  title: "NYC Safety App: Optimized Vision Analysis System"
  subtitle: "From Complex AI to Efficient Numerical Analysis"
  authors: ["NYC Safety Team"]
  date: "June 22, 2025"
  hackathon: "Nice People Hackathon"

# Performance metrics - before and after optimization
performance:
  api_calls:
    before: 8
    after: 1
    reduction_percent: 87.5
  
  analysis_time:
    before_seconds: 60
    after_seconds: 15
    improvement_percent: 75
  
  success_rate:
    before_percent: 40
    after_percent: 90
    improvement_percent: 125
  
  code_size:
    before_lines: 1000
    after_lines: 200
    reduction_percent: 80

# Vision analysis variables
vision_variables:
  categories:
    - name: "Bikes"
      positions: ["sidewalk", "street", "bike_lane", "crosswalk", "parked"]
      color: "#FF6B6B"
    - name: "People" 
      positions: ["sidewalk", "street", "crosswalk", "waiting", "moving"]
      color: "#4ECDC4"
    - name: "Vehicles"
      positions: ["moving", "stopped", "parked", "turning", "blocking"]
      color: "#45B7D1"
    - name: "Activity"
      positions: ["pedestrian", "cycling", "traffic", "construction", "emergency"]
      color: "#96CEB4"
    - name: "Infrastructure"
      positions: ["signals", "signs", "lanes", "barriers", "lighting"]
      color: "#FFEAA7"

# System architecture components
architecture:
  components:
    - name: "Vision Config"
      file: "config/visionConfig.ts"
      responsibility: "25 encoded variables (0-4)"
      color: "#FF6B6B"
    - name: "Moondream Service"
      file: "services/moondreamService.ts"
      responsibility: "Pure vision analysis only"
      color: "#4ECDC4"
    - name: "AsyncStorage"
      file: "services/asyncStorageService.ts"
      responsibility: "Central data hub"
      color: "#45B7D1"
    - name: "Interpretation Service"
      file: "services/visionInterpretationService.ts"
      responsibility: "Post-processing & analysis"
      color: "#96CEB4"
    - name: "NYC Camera Service"
      file: "services/nycCameraService.ts"
      responsibility: "Territory integration"
      color: "#FFEAA7"

# Discovery timeline - Based on actual development log
discovery:
  phases:
    - phase: "Day 1: Initial Setup & Testing"
      description: "June 21: App testing, rate limiting discovery"
      duration_hours: 8
      issues: ["429 rate limit errors", "6-8 API calls per analysis", "60s processing time", "40% success rate"]
    
    - phase: "Day 1 Evening: Numerical Analysis"
      description: "June 21: First optimization attempt"
      duration_hours: 4
      improvements: ["Single API call", "Feature matrix system", "Mathematical scoring"]
    
    - phase: "Day 2 Morning: Config-Based Breakthrough"
      description: "June 22: Encoded categories innovation"
      duration_hours: 6
      breakthrough: ["25 encoded variables (0-4)", "Pure numerical exchange", "87.5% API reduction"]
    
    - phase: "Day 2 Afternoon: AsyncStorage Integration"
      description: "June 22: Territory system integration"
      duration_hours: 6
      features: ["Central data hub", "Persistent Voronoi cells", "Territory integration", "Code reduction 1000â†’200 lines"]

# Mathematical formulas
formulas:
  core_metrics:
    - name: "Active Cycling"
      formula: "bikes_street*1.5 + bikes_bike_lane*0.8 + bikes_crosswalk*2.0"
      description: "Weighted sum of bike positions"
    
    - name: "Pedestrian Safety"
      formula: "max(0, 4-people_street) + infrastructure_bonus*0.5"
      description: "Street safety with infrastructure bonus"
    
    - name: "Traffic Pressure"
      formula: "vehicles_moving*0.8 + vehicles_stopped*1.2 + vehicles_blocking*2.0"
      description: "Weighted vehicle congestion"

  multi_variable:
    - name: "Bike Conflict Zones"
      formula: "min(bikes_street, vehicles_moving) * 2"
      description: "Intersection of bikes and traffic"
    
    - name: "Pedestrian Exposure"
      formula: "people_street*2.0 + people_crosswalk*vehicles_turning"
      description: "People in vulnerable positions"

# Limits and challenges discovered
limits:
  vision_model:
    caption_issues:
      - "Inconsistent text responses"
      - "Ambiguous descriptions"
      - "Context-dependent interpretations"
      - "Rate limiting with multiple calls"
    
    improvements_with_encoding:
      - "Consistent numerical responses"
      - "Structured data format"
      - "Reduced compute footprint"
      - "Single API call efficiency"
  
  original_approach:
    problems:
      - "8 sequential API calls per analysis"
      - "60+ second processing time"
      - "40% success rate due to failures"
      - "Complex text parsing logic"
    
    solutions:
      - "1 optimized API call"
      - "15 second processing time"
      - "90% success rate"
      - "Mathematical operations on numbers"

# Visual state management
visual_states:
  - state: "Unprocessed"
    description: "Blurry zones (0.2 alpha)"
    hex_color: "#CCCCCC"
    alpha: 0.2
    trigger: "Camera zones not yet analyzed"
  
  - state: "Sakura Pink"
    description: "Zones queued for processing"
    hex_color: "#FFB7C5"
    alpha: 0.8
    trigger: "User within 500m radius"
  
  - state: "Blinking"
    description: "Active processing"
    hex_color: "#FFA500"
    alpha: 1.0
    trigger: "API call in progress"
  
  - state: "Heat Colors"
    description: "Completed analysis"
    hex_color: "#00FF00"
    alpha: 0.9
    trigger: "Analysis finished"
  
  - state: "Error Red"
    description: "Failed analysis"
    hex_color: "#FF0000"
    alpha: 0.8
    trigger: "API call failed"

# Output settings
output:
  folder: "presentation/assets"
  formats: ["png", "svg"]
  dpi: 300
  figsize: [10, 6]  # Reduced to reasonable size for web display
  style: "seaborn-v0_8" 